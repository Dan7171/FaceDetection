{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# an Overall code for CF and head views analysis for all csvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from pathlib import Path\n",
    "import openpyxl\n",
    "import os\n",
    "import re\n",
    "import ggplot\n",
    "from openpyxl import load_workbook\n",
    "import xlsxwriter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "experiments_folder: the folder with all the experiments we want to plot and make csvs for\n",
    "\n",
    "regex: the text we take from logs in each results to extract the threshold\n",
    "\n",
    "plot_kwards: the args for the results plot\n",
    "\n",
    "save..: if we want to save the plot/csv data of the results\n",
    "\n",
    "plot folder:dest path to save the plots\n",
    "\n",
    "mean_std_folder: dest path to csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_folder = Path('/home/administrator/experiments/all_ids/500_ids')\n",
    "# experiments_folder = Path('/home/administrator/experiments/frontal_vs_variable')\n",
    "regex =' (.*) threshold\\\\nlayer\\s*\\\\n(\\d*)(\\s+)(\\d*.\\d*)(\\s+)(\\d*.\\d*)\\\\n(\\d*)(\\s+)(\\d*.\\d*)(\\s+)(\\d*.\\d*)\\\\n(\\d*)(\\s+)(\\d*.\\d*)(\\s+)(\\d*.\\d*)'\n",
    "plot_kwargs={'grid':True,'figsize':(20,8), 'fontsize':12}\n",
    "save_views_plot = 0\n",
    "save_cf_plot = 0\n",
    "save_views_csv = 0\n",
    "save_cf_csv = 0\n",
    "save_mean_views_csv = 1\n",
    "save_mean_cf_csv = 1\n",
    "save_std_views_csv = 0\n",
    "save_std_cf_csv = 0\n",
    "save_se_views_csv = 1\n",
    "save_se_cf_csv = 1\n",
    "mean_std_folder=''\n",
    "plots_folder = '/home/administrator/plot_results/all_ids/500_test/500_ids_num_changed/'\n",
    "# plots_folder = '/home/administrator/plot_results/frontal_vs_variable/'\n",
    "mean_folder_views='/home/administrator/plot_results/all_ids/500_test/500_ids_num_changed/csv/mean/views/'\n",
    "std_folder_views='/home/administrator/plot_results/all_ids/500_test/500_ids_num_changed/csv/std/views/'\n",
    "se_folder_views='/home/administrator/plot_results/all_ids/500_test/500_ids_num_changed/csv/se/views/'\n",
    "mean_folder_cf='/home/administrator/plot_results/all_ids/500_test/500_ids_num_changed/csv/mean/cf/'\n",
    "std_folder_cf='/home/administrator/plot_results/all_ids/500_test/500_ids_num_changed/csv/std/cf/'\n",
    "se_folder_cf='/home/administrator/plot_results/all_ids/500_test/500_ids_num_changed/csv/se/cf/'\n",
    "\n",
    "csv_list=[]\n",
    "add_to_title = 'gaus_2'\n",
    "excel_title = '500_ids'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make the csvs list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/administrator/experiments/all_ids/500_test/500_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-7da2f10c6ae4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mexperiment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiments_folder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mcsv_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     csv_path = (os.path.join(Path(experiment),'vgg16/results/comparisons_with_fc7_linear.csv'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcsv_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'vgg16/results/comparisons_with_fc7_linear_blurred_Gaus_2.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcsv_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/facial_feature_impact_comparison/lib/python3.8/pathlib.py\u001b[0m in \u001b[0;36miterdir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'..'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m                 \u001b[0;31m# Yielding a path object for these makes little sense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/administrator/experiments/all_ids/500_test/500_ids'"
     ]
    }
   ],
   "source": [
    "for experiment in experiments_folder.iterdir():\n",
    "    csv_path=''\n",
    "#     csv_path = (os.path.join(Path(experiment),'vgg16/results/comparisons_with_fc7_linear.csv'))\n",
    "    csv_path = (os.path.join(Path(experiment),'vgg16/results/comparisons_with_fc7_linear_blurred_Gaus_2.csv'))\n",
    "    csv_list.append(csv_path)\n",
    "# csv_list = ['/home/administrator/experiments/500_ids/500_ids_300_train/vgg16/results/comparisons_with_fc7_linear.csv']\n",
    "# csv_list = ['/home/administrator/experiments//1000_ids_20_train/vgg16/results/comparisons_with_fc7_linear.csv']\n",
    "# csv_list = ['/home/administrator/experiments/500_ids/500_ids_100_train/vgg16/results/comparisons_with_fc7_linear_blurred_Gaus_2.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    results of the threshold extraction:\n",
    "    results.group(2) = 38\n",
    "    results.group(4) = accuracy (38) \n",
    "    results.group(6) = threshold (38)\n",
    "    \n",
    "    results.group(7) = 37\n",
    "    results.group(9) = accuracy (37) \n",
    "    results.group(11) = threshold (37)\n",
    "    \n",
    "    results.group(12) = 39\n",
    "    results.group(14) = accuracy (39) \n",
    "    results.group(16) = threshold (39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv_file in csv_list:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    splited = csv_file.split('/') \n",
    "    #normal:\n",
    "#     base_title = splited[splited.index('experiments')+2]\n",
    "#     base_title = (base_title.split('img'))[0][:-1]\n",
    "# #for 1000:\n",
    "#     base_title = (base_title.split('train'))[0]\n",
    "# for 500:\n",
    "    base_title = splited[splited.index('experiments')+3]\n",
    "    base_title = (base_title.split('img'))[0][:-1]\n",
    "    print(base_title)\n",
    "    \n",
    "    p = os.path.join(Path(csv_file).parents[1], 'results')\n",
    "    if os.path.exists(os.path.join(p, 'logs.csv')):\n",
    "        csv_threshold = 1\n",
    "        threshold_file = os.path.join(p, 'logs.csv')\n",
    "    else:\n",
    "        csv_threshold = 0\n",
    "        threshold_file = os.path.join(Path(csv_file).parents[2], 'logs')\n",
    "    #extract threshold\n",
    "    with open(threshold_file) as fo:\n",
    "        if csv_threshold == 0:\n",
    "            logs = fo.read()\n",
    "            results = re.search(regex,logs)\n",
    "            threshold37 = float(results.group(11)) \n",
    "        else:\n",
    "            df_threshold = pd.read_csv(fo)\n",
    "            threshold37 = df_threshold.loc[1,'threshold']\n",
    "\n",
    "    \n",
    "    # change unnamed column to 'pairs'\n",
    "    df = df.rename(columns = {'Unnamed: 0':'pairs'})\n",
    "    \n",
    "    #split the tuples to two columns\n",
    "    df_splited = df['pairs'].str.split(',', expand=True)\n",
    "\n",
    "    #adding   \n",
    "    df.insert(loc=0, column='img1', value=df_splited[0] )\n",
    "    df.insert(loc=1, column='img2', value=df_splited[1] )\n",
    "\n",
    "\n",
    "    # Dropping old Name columns \n",
    "    df.drop(columns =[\"pairs\"], inplace = True) \n",
    "    \n",
    "    #reorder columns by layer order\n",
    "    df = df[['img1', 'img2', 'input', 'conv1', 'conv2', 'conv3', 'conv4', 'conv5', 'fc6', 'fc7', 'fc8','type' ]]\n",
    "\n",
    "\n",
    "    ##################head views###################\n",
    "    \n",
    "    title = base_title +'_views_'+add_to_title\n",
    "\n",
    "    #change frontal-ref to frontal_ref\n",
    "    df['type'] = df['type'].replace(['frontal-ref'],'frontal_ref')\n",
    "\n",
    "\n",
    "    #change frontal-quarter_left to frontal_quarter_left\n",
    "    df['type'] = df['type'].replace(['frontal-quarter_left'],'frontal_quarter_left')\n",
    "\n",
    "\n",
    "    #change frontal-half_left to frontal_half_left\n",
    "    df['type'] = df['type'].replace(['frontal-half_left'],'frontal_half_left')\n",
    "\n",
    "    #remove  HPS,LPS,SAME type.\n",
    "    # df = df[df.type.str.contains(\"same_pairs|frontal|diff_pairs\")]\n",
    "    df1 = df[df.type.str.contains(\"frontal|diff_pairs\")]\n",
    "\n",
    "    df2 = df1[df1.type.str.contains(\"same_pairs|diff_pairs\")]\n",
    "    # df1 = df[df['type'] =='diff_pairs'|df['type']=='same_pairs']\n",
    "    df3 = df2[df2.img1.str.contains(\"CM\")] \n",
    "    # df3 = df[df['type'] !='diff_pairs'&df['type'] !='same_pairs']\n",
    "    df4 = df1[~df1.type.str.contains(\"same_pairs|diff_pairs\")]\n",
    "\n",
    "    df_views = pd.concat([df3,df4])\n",
    "    df_views.reset_index()\n",
    "    max_value_df = df_views.max()\n",
    "    max_value_df\n",
    "    df_views = df_views.reset_index(drop=True)\n",
    "    \n",
    "    df_views = df_views.drop(columns=['img1', 'img2'])\n",
    "    normalized_threshold_views = threshold37/max_value_df['fc7']\n",
    "    \n",
    "    for x in df_views.drop(columns=['type']).columns:\n",
    "        df_views[x]= (df_views[x]/df_views[x].max()) \n",
    "    \n",
    "    #df of size of each type\n",
    "    size_df_views = df_views.groupby(['type']).count()\n",
    "    sqrt_size_views = np.sqrt(size_df_views)\n",
    "    \n",
    "    #mean of each columns by type of pairs\n",
    "    means_df_views = df_views.groupby(['type']).mean()\n",
    "    means_df_views = means_df_views.rename_axis(\"layers\", axis=\"columns\")\n",
    "    means_df_views = means_df_views.transpose()\n",
    "\n",
    "    \n",
    "    std_views = df_views.groupby(['type']).std()\n",
    "    std_views = std_views.transpose()\n",
    "    \n",
    "    #standard error of mean\n",
    "    se_views = std_views.transpose().div(sqrt_size_views).transpose()\n",
    "    \n",
    "    #combine means and std df to one:\n",
    "    columns = means_df_views.columns.copy()\n",
    "    rows =  means_df_views.index.copy()\n",
    "    header = pd.MultiIndex.from_product([columns,\n",
    "                                         ['mean','STD']],\n",
    "                                        names=['type','mean/STD'])\n",
    "    df_means_std = pd.DataFrame( \n",
    "                      index=rows, \n",
    "                      columns=header)\n",
    "\n",
    "    df_means_std[('diff_pairs','mean')] = means_df_views.diff_pairs.copy()\n",
    "    df_means_std[('diff_pairs','STD')] = std_views.diff_pairs.copy()\n",
    "    \n",
    "    df_means_std[('frontal_half_left','mean')] = means_df_views.frontal_half_left.copy()\n",
    "    df_means_std[('frontal_half_left','STD')] = std_views.frontal_half_left.copy()\n",
    "    \n",
    "    df_means_std[('frontal_quarter_left','mean')] = means_df_views.frontal_quarter_left.copy()\n",
    "    df_means_std[('frontal_quarter_left','STD')] = std_views.frontal_quarter_left.copy()\n",
    "    \n",
    "    df_means_std[('frontal_ref','mean')] = means_df_views.frontal_ref.copy()\n",
    "    df_means_std[('frontal_ref','STD')] = std_views.frontal_ref.copy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    #save to csv/excel\n",
    "\n",
    "    if (save_views_csv == 1):\n",
    "\n",
    "        excel_book = mean_std_folder+add_to_title+'/'+excel_title+'.xlsx'\n",
    "        sheet = title+'_mean_std'\n",
    "        if  os.path.exists(excel_book):\n",
    "            with pd.ExcelWriter(excel_book, engine='openpyxl', mode='a') as writer:  \n",
    "                df_means_std.to_excel(writer, sheet_name=sheet)\n",
    "\n",
    "        else:\n",
    "            with pd.ExcelWriter(excel_book) as writer:  \n",
    "                df_means_std.to_excel(writer, sheet_name=sheet)\n",
    "    if (save_mean_views_csv == 1):\n",
    "        excel_book = mean_folder_views+add_to_title+'/'+excel_title+'.xlsx'\n",
    "        sheet = title+'_mean'\n",
    "        if  os.path.exists(excel_book):\n",
    "            with pd.ExcelWriter(excel_book, engine='openpyxl', mode='a') as writer:  \n",
    "                means_df_views.to_excel(writer, sheet_name=sheet)\n",
    "\n",
    "        else:\n",
    "            with pd.ExcelWriter(excel_book) as writer:  \n",
    "                means_df_views.to_excel(writer, sheet_name=sheet)\n",
    "                \n",
    "    if (save_std_views_csv == 1):\n",
    "        excel_book = std_folder_views+add_to_title+'/'+excel_title+'.xlsx'\n",
    "        sheet = title+'_std'\n",
    "        if  os.path.exists(excel_book):\n",
    "            with pd.ExcelWriter(excel_book, engine='openpyxl', mode='a') as writer:  \n",
    "                std_views.to_excel(writer, sheet_name=sheet)\n",
    "\n",
    "        else:\n",
    "            with pd.ExcelWriter(excel_book) as writer:  \n",
    "                std_views.to_excel(writer, sheet_name=sheet)\n",
    "    \n",
    "    if (save_se_views_csv == 1):\n",
    "        excel_book = se_folder_views+add_to_title+'/'+excel_title+'.xlsx'\n",
    "        sheet = title+'_se'\n",
    "        if  os.path.exists(excel_book):\n",
    "            with pd.ExcelWriter(excel_book, engine='openpyxl', mode='a') as writer:  \n",
    "                se_views.to_excel(writer, sheet_name=sheet)\n",
    "\n",
    "        else:\n",
    "            with pd.ExcelWriter(excel_book) as writer:  \n",
    "                se_views.to_excel(writer, sheet_name=sheet)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "#     #plot\n",
    "#     plot = means_df_views.plot(**plot_kwargs, title = title, ylim = [0,1], lw=4)\n",
    "#     plt.scatter(7, normalized_treshold_views, color='black')\n",
    "\n",
    "    #plot\n",
    "    #with std bars\n",
    "#     score_lower_limit1 = means_df_views - std_views\n",
    "#     score_upper_limit1 = means_df_views + std_views\n",
    "    #with SE bars\n",
    "    score_lower_limit1 = means_df_views - se_views\n",
    "    score_upper_limit1 = means_df_views + se_views\n",
    "    COLORS = \"blue\", \"yellow\", \"green\", \"red\"\n",
    "    \n",
    "    param_fig1, param_ax1 = plt.subplots(sharex = 'all', figsize=(20,10))\n",
    "    plt.ylim(0, 1)\n",
    "    param_ax1.set_title(title)\n",
    "\n",
    "    param_ax1.plot(means_df_views, marker='.', lw=4)\n",
    "    plt.legend( ['diff_pairs', 'frontal_half_left','frontal_quarter_left','frontal_ref'])#?????\n",
    "\n",
    "\n",
    "\n",
    "    for i, col in enumerate(means_df_views.columns):\n",
    "            param_ax1.fill_between(means_df_views.index,\n",
    "                              score_lower_limit1[col],\n",
    "                              score_upper_limit1[col],\n",
    "                              color=COLORS[i],\n",
    "                              alpha=0.1)\n",
    "    param_ax1.scatter(7, normalized_threshold_views, color='black')\n",
    "    matplotlib.rcParams.update({'font.size': 20})\n",
    "#     plt.rcParams[\"font.family\"] = \"Humor Sans\"\n",
    "\n",
    "    \n",
    "    #save plot\n",
    "    if (save_views_plot==1):\n",
    "        plt.savefig(plots_folder+'/head_views/'+title)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    #################critical features#################\n",
    "    title = base_title +'_cf_'+add_to_title\n",
    "    \n",
    "    #remove all last rows - save only DIFF,HPS,LPS,SAME type.\n",
    "    df_cf = df[~df.type.str.contains(\"frontal\")]\n",
    "    \n",
    "    #max values df\n",
    "    max_value_df = df_cf.max()\n",
    "    \n",
    "    df_cf = df_cf.reset_index(drop=True)\n",
    "    df_cf = df_cf.drop(columns=['img1', 'img2'])\n",
    "    \n",
    "    #normalized threshold\n",
    "    normalized_threshold_cf = threshold37/max_value_df['fc7']\n",
    "    \n",
    "    #\n",
    "    for x in df_cf.drop(columns=['type']).columns:\n",
    "        df_cf[x]= (df_cf[x]/df_cf[x].max()) \n",
    "    \n",
    "    #df of size of each type\n",
    "    size_df_cf = df_cf.groupby(['type']).count()\n",
    "    sqrt_size_cf = np.sqrt(size_df_cf)\n",
    "    \n",
    "    #mean of each columns by type of pairs\n",
    "    means_df_cf = df_cf.groupby(['type']).mean()\n",
    "    means_df_cf = means_df_cf.rename_axis(\"layers\", axis=\"columns\")\n",
    "    means_df_cf = means_df_cf.transpose()\n",
    "    \n",
    "    #standard deviation\n",
    "    std_cf = df_cf.groupby(['type']).std()\n",
    "    std_cf = std_cf.transpose()\n",
    "    \n",
    "    #standard error of mean\n",
    "    se_cf = std_cf.transpose().div(sqrt_size_cf).transpose()\n",
    "    \n",
    "    #combine means and std df to one:\n",
    "    columns_cf = means_df_cf.columns.copy()\n",
    "    rows_cf =  means_df_cf.index.copy()\n",
    "    header_cf = pd.MultiIndex.from_product([columns_cf,\n",
    "                                         ['mean','STD']],\n",
    "                                        names=['type','mean/STD'])\n",
    "    df_means_std_cf = pd.DataFrame( \n",
    "                      index=rows_cf, \n",
    "                      columns=header_cf)\n",
    "\n",
    "    df_means_std_cf[('diff_pairs','mean')] = means_df_cf.diff_pairs.copy()\n",
    "    df_means_std_cf[('diff_pairs','STD')] = std_cf.diff_pairs.copy()\n",
    "    \n",
    "    df_means_std_cf[('high_ps_pairs','mean')] = means_df_cf.high_ps_pairs.copy()\n",
    "    df_means_std_cf[('high_ps_pairs','STD')] = std_cf.high_ps_pairs.copy()\n",
    "    \n",
    "    df_means_std_cf[('low_ps_pairs','mean')] = means_df_cf.low_ps_pairs.copy()\n",
    "    df_means_std_cf[('low_ps_pairs','STD')] = std_cf.low_ps_pairs.copy()\n",
    "    \n",
    "    df_means_std_cf[('same_pairs','mean')] = means_df_cf.same_pairs.copy()\n",
    "    df_means_std_cf[('same_pairs','STD')] = std_cf.same_pairs.copy()\n",
    "    \n",
    "    \n",
    "    #save to csv/excel\n",
    "    \n",
    "    if (save_cf_csv == 1):\n",
    "\n",
    "        excel_book = mean_std_folder+add_to_title+'/'+excel_title+'.xlsx'\n",
    "        sheet = title+'_mean_std'\n",
    "        if  os.path.exists(excel_book):\n",
    "            with pd.ExcelWriter(excel_book, engine='openpyxl', mode='a') as writer:  \n",
    "                df_means_std_cf.to_excel(writer, sheet_name=sheet)\n",
    "\n",
    "        else:\n",
    "            with pd.ExcelWriter(excel_book) as writer:  \n",
    "                df_means_std_cf.to_excel(writer, sheet_name=sheet)\n",
    "    if (save_mean_cf_csv == 1):\n",
    "        excel_book = mean_folder_cf+add_to_title+'/'+excel_title+'.xlsx'\n",
    "        sheet = title+'_mean'\n",
    "        if  os.path.exists(excel_book):\n",
    "            with pd.ExcelWriter(excel_book, engine='openpyxl', mode='a') as writer:  \n",
    "                means_df_cf.to_excel(writer, sheet_name=sheet)\n",
    "\n",
    "        else:\n",
    "            with pd.ExcelWriter(excel_book) as writer:  \n",
    "                means_df_cf.to_excel(writer, sheet_name=sheet)\n",
    "\n",
    "    if (save_std_cf_csv == 1):\n",
    "        excel_book = std_folder_cf+add_to_title+'/'+excel_title+'.xlsx'\n",
    "        sheet = title+'_std'\n",
    "        if  os.path.exists(excel_book):\n",
    "            with pd.ExcelWriter(excel_book, engine='openpyxl', mode='a') as writer:  \n",
    "                std_cf.to_excel(writer, sheet_name=sheet)\n",
    "\n",
    "        else:\n",
    "            with pd.ExcelWriter(excel_book) as writer:  \n",
    "                std_cf.to_excel(writer, sheet_name=sheet)\n",
    "                \n",
    "    if (save_se_cf_csv == 1):\n",
    "        excel_book = se_folder_cf+add_to_title+'/'+excel_title+'.xlsx'\n",
    "        sheet = title+'_se'\n",
    "        if  os.path.exists(excel_book):\n",
    "            with pd.ExcelWriter(excel_book, engine='openpyxl', mode='a') as writer:  \n",
    "                se_cf.to_excel(writer, sheet_name=sheet)\n",
    "\n",
    "        else:\n",
    "            with pd.ExcelWriter(excel_book) as writer:  \n",
    "                se_cf.to_excel(writer, sheet_name=sheet)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#     if (save_cf_csv == 1):\n",
    "#         df_means_std_cf.to_csv(mean_std_folder+title+'_mean_std')\n",
    "#         # df.to_excel(\"output.xlsx\", sheet_name='Sheet_name_1')  \n",
    "#     if (save_mean_cf_csv == 1):\n",
    "# #         means_df_cf.to_csv(mean_folder+'/mean/'+title+'_mean')\n",
    "#     # df.to_excel(\"output.xlsx\", sheet_name='Sheet_name_1') \n",
    "#         means_df_cf.to_excel(mean_folder+'mean/'+add_to_title+'/'+excel_title+'.xlsx', sheet_name=title+'_mean') \n",
    "\n",
    "#     if (save_std_cf_csv == 1):\n",
    "#         std_cf.to_csv(std_folder+'/std/'+title+'_std')\n",
    "#     # df.to_excel(\"output.xlsx\", sheet_name='Sheet_name_1') \n",
    "\n",
    "    #plot\n",
    "    score_lower_limit = means_df_cf - se_cf\n",
    "    score_upper_limit = means_df_cf + se_cf\n",
    "    COLORS = \"blue\", \"yellow\", \"green\", \"red\"\n",
    "    \n",
    "    param_fig, param_ax = plt.subplots(sharex = 'all', figsize=(20,10))\n",
    "    plt.ylim(0, 1)\n",
    "    param_ax.set_title(title)\n",
    "\n",
    "    param_ax.plot(means_df_cf, marker='.', lw=4)\n",
    "    plt.legend( ['diff_pairs', 'high_ps_pairs','low_ps_pairs','same_pairs'])#?????\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "#     arr1 =param_ax.plot(means_df_cf.diff_pairs, marker='*', lw=4, label = 'diff_pairs')\n",
    "#     arr2 = param_ax.plot(means_df_cf.high_ps_pairs, marker='*', lw=4, label = 'hps')\n",
    "#     arr3 = param_ax.plot(means_df_cf.low_ps_pairs, marker='*', lw=4, label = 'lps')\n",
    "#     arr4 =param_ax.plot(means_df_cf.same_pairs, marker='*', lw=4, label = 'same')\n",
    "#     plt.legend([arr1, arr2, arr3, arr4], ['diff_pairs','high_ps_pairs','low_ps_pairs','same_pairs'])\n",
    "#     plot = means_df_cf.plot(**plot_kwargs, title = title, ylim = [0,1], lw=4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for i, col in enumerate(means_df_cf.columns):\n",
    "            param_ax.fill_between(means_df_cf.index,\n",
    "                              score_lower_limit[col],\n",
    "                              score_upper_limit[col],\n",
    "                              color=COLORS[i],\n",
    "                              alpha=0.1)\n",
    "    param_ax.scatter(7, normalized_threshold_cf, color='black')\n",
    "    matplotlib.rcParams.update({'font.size': 20})\n",
    "#     plt.rcParams[\"font.family\"] = \"Humor Sans\"\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    #save plot\n",
    "    if (save_cf_plot==1):\n",
    "        plt.savefig(plots_folder+'/cf/'+title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
